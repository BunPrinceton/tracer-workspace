{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6502d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "just get synapse counts for root id\n",
    "get synapses in bounding box\n",
    "linkbuilder (generalize)\n",
    "ID rough spot checker\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b925d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synapse_counts(root_ids, datastack, cleft_thresh=0):\n",
    "    \"\"\"Get synapse counts for a list of root IDs.\n",
    "    \n",
    "    Arguments:\n",
    "    root_ids -- a list of root IDs to get synapse counts for (list of int or str, will also accept a single int or str)\n",
    "    datastack -- the name of the datastack the IDs are from (str)\n",
    "    cleft_thresh -- the cleft score bleow which to exclude synapses, currently only works with \"flywire_fafb_production\" datastack (int, default 0)\n",
    "    \n",
    "    Returns:\n",
    "    synapse_dict -- a dictionary containing the requested synapse counts\n",
    "    \"\"\"\n",
    "\n",
    "    # returns error if cleft thresholding is used with non-flywire datasets #\n",
    "    if datastack != \"flywire_fafb_production\" and cleft_thresh != 0:\n",
    "        raise ValueError(\"Cleft thresholding currently only works for the 'flywire_fafb_production' dataset.\")\n",
    "\n",
    "    ### CURRENTLY ASSUMES CLEFT SCORE COLUMN NAME IS \"cleft_score\", ONLY WORKS WITH FLYWIRE ###\n",
    "    cleft_score_column_name = \"cleft_score\"\n",
    "\n",
    "    # sets CAVE client object using datastack name #\n",
    "    client = CAVEclient(datastack_name=datastack)\n",
    "\n",
    "    # gets metadata for chosen datastack as dict #\n",
    "    stack_info = client.info.get_datastack_info()\n",
    "\n",
    "    # gets name of synapse table using stack_info #\n",
    "    synapse_table_name = stack_info[\"synapse_table\"]\n",
    "\n",
    "    # converts root IDs to list of integers for passing into query_table method #\n",
    "    root_ids = list(map(int, root_ids))\n",
    "\n",
    "    # creates empty synapse dict to fill with counts #\n",
    "    synapse_dict = {}\n",
    "\n",
    "    # iterates over root IDs to get synapse counts #\n",
    "    for root_id in root_ids:\n",
    "        in_df = client.materialize.query_table(\n",
    "                synapse_table_name,\n",
    "                filter_in_dict={\"post_pt_root_id\": [root_id]},\n",
    "            )\n",
    "        out_df = client.materialize.query_table(\n",
    "                synapse_table_name,\n",
    "                filter_in_dict={\"pre_pt_root_id\": [root_id]},\n",
    "            )\n",
    "        \n",
    "        # drops synapses if asked #\n",
    "        if cleft_thresh > 0:\n",
    "            in_df = in_df[\n",
    "                in_df[cleft_score_column_name] >= float(cleft_thresh)\n",
    "            ].reset_index(drop=True)\n",
    "            out_df = out_df[\n",
    "                out_df[cleft_score_column_name] >= float(cleft_thresh)\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "        # gets synapse counts by counting length of dfs #\n",
    "        incoming = len(in_df)\n",
    "        outgoing = len(out_df)\n",
    "\n",
    "        # adds values to synapse dict #\n",
    "        synapse_dict[str(root_id)] = {\n",
    "            \"incoming\" : incoming,\n",
    "            \"outgoing\" : outgoing,\n",
    "            \"total\" : incoming + outgoing,\n",
    "        }\n",
    "    \n",
    "    return synapse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7ad691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'720575941498482043': {'incoming': 2001, 'outgoing': 12520, 'total': 14521},\n",
       " '720575941619873407': {'incoming': 7911, 'outgoing': 26319, 'total': 34230},\n",
       " '720575941628378338': {'incoming': 323, 'outgoing': 551, 'total': 874}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synapse_counts([720575941498482043, 720575941619873407, 720575941628378338],\"brain_and_nerve_cord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dde84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REBUILD PROCEDURE #\n",
    "\n",
    "# git pull ; pip uninstall tracer_tools ; python -m pip install -e \"F:\\Archive Backup\\Jay\\Work Related\\Work Apps\\tracer_tools\"\n",
    "\n",
    "# FOR LAPTOP #\n",
    "# git pull ; pip uninstall tracer_tools ; python -m pip install -e \"C:\\Users\\jgager\\coding\\tracer_tools\"\n",
    "\n",
    "\n",
    "# python -m build;pip uninstall tracer_tools;python -m pip install -e \"F:\\Archive Backup\\Jay\\Work Related\\Work Apps\\tracer_tools\"\n",
    "\n",
    "# python -m build\n",
    "# pip uninstall tracer_tools\n",
    "# python -m pip install -e \"F:\\Archive Backup\\Jay\\Work Related\\Work Apps\\tracer_tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6344a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudvolume\n",
    "from caveclient import CAVEclient\n",
    "import pandas as pd\n",
    "from nglui.statebuilder import *\n",
    "import json\n",
    "from osteoid import Skeleton\n",
    "import numpy as np\n",
    "import microviewer\n",
    "import time\n",
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "import statistics\n",
    "\n",
    "import tracer_tools as tt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fe1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_coord_list = [[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]    \n",
    "nm_bbox_list = [[tt.convert_coord_res(point,res_current=[4,4,40]) for point in bbox] for bbox in bbox_coord_list]\n",
    "print(nm_bbox_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(point_a, point_b, xyz_resolution):\n",
    "    \"\"\"Calculate distance in 3D between two points in nanometers based on the viewer resolution.\n",
    "    \n",
    "    Arguments:\n",
    "    point_a -- xyz coordinates of first point (list of ints)\n",
    "    point_b -- xyz coordinates of second point (list of ints)\n",
    "    xyz_resolution -- the nanometers per voxel in the x, y, and z directions (list of ints)\n",
    "\n",
    "    Returns:\n",
    "    dist -- the 3D distance in nanometers between points a and b\"\"\"\n",
    "\n",
    "    # calculates distance in x, y, and z dimensions #\n",
    "    xdist = (xyz_resolution[0] * point_a[0]) - (xyz_resolution[0] * point_b[0])\n",
    "    ydist = (xyz_resolution[1] * point_a[1]) - (xyz_resolution[1] * point_b[1])\n",
    "    zdist = (xyz_resolution[2] * point_a[2]) - (xyz_resolution[2] * point_b[2])\n",
    "\n",
    "    # uses distance formula to calculate distance in 3D #\n",
    "    dist = ((xdist ** 2) + (ydist ** 2) + (zdist ** 2)) ** 0.5\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_distance([145983, 59737, 3304],[147352, 59765, 3184],[4,4,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58435a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.get_stack_data(\"brain_and_nerve_cord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datastack_config(datastack):\n",
    "    \"\"\"Get relevant information for a given datastack\"\"\"\n",
    "    \n",
    "    # sets CAVE client object using datastack name #\n",
    "    client = CAVEclient(datastack_name=datastack)\n",
    "\n",
    "    # gets metadata for chosen datastack as dict #\n",
    "    stack_info = client.info.get_datastack_info()\n",
    "    \n",
    "    pprint(stack_info)\n",
    "\n",
    "    if datastack == \"flywire_fafb_production\":\n",
    "        config = {\n",
    "            \"datastack_name\" : datastack,\n",
    "            \"em_url\":stack_info[\"aligned_volume\"][\"image_source\"],\n",
    "            \"segmentation_url\":stack_info[\"segmentation_source\"],\n",
    "            \"viewer_resolution\":[\n",
    "                stack_info[\"viewer_resolution_x\"],\n",
    "                stack_info[\"viewer_resolution_y\"],\n",
    "                stack_info[\"viewer_resolution_z\"],   \n",
    "            ],\n",
    "            \"synapse_table_name\" : stack_info[\"synapse_table\"],\n",
    "            \"incoming_syn_col_name\":\"post_pt_root_id\",\n",
    "            \"outgoing_syn_col_name\":\"pre_pt_root_id\",\n",
    "            \"nucleus_table\":stack_info[\"soma_table\"],\n",
    "            \"skeleton_url\":stack_info[\"skeleton_source\"],\n",
    "            \"recommended_syn_cleft_thresh\":50,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_datastack_config(\"flywire_fafb_production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [out_nt, in_dict, in_plot] = get_nt(720575940651305718, \"flywire_fafb_production\", incoming=True)\n",
    "# print(out_nt)\n",
    "# pprint(in_dict)\n",
    "# in_plot.show()\n",
    "\n",
    "nt_list = tt.get_nt([720575940651305718,720575940626405690,720575940618680550], \"flywire_fafb_production\")\n",
    "print(nt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b080d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roots_to_nt_link(root_ids, datastack):\n",
    "    \"\"\"Generate a neuroglancer link from a list of root IDs color coded by dominant outgoing synapse neurotransmitter. CURRENTLY ONLY WORKS WITH FLYWIRE\n",
    "    \n",
    "    Arguments:\n",
    "    root_ids -- a list of root IDs (list of int or str)\n",
    "    datastack -- the name of the datastack the root IDs are from (str)\n",
    "\n",
    "    Returns:\n",
    "    link -- a neuroglancer url with nt-color-coded segments (str)\n",
    "    \"\"\"\n",
    "\n",
    "    # gets dominant outgoing neurotransmitters for list of root IDs #\n",
    "    nts = tt.get_nt(root_ids, datastack)\n",
    "\n",
    "    # creates empty list to fill with nt-paired hex values for color coding #\n",
    "    color_list = []\n",
    "\n",
    "    # adds hex values to color list based on dominant nt for each ID #\n",
    "    for nt in nts:\n",
    "        if nt == \"ach\":\n",
    "            color_list.append(\"#ff4958\")\n",
    "        elif nt == \"da\":\n",
    "            color_list.append(\"#ff944d\")\n",
    "        elif nt == \"gaba\":\n",
    "            color_list.append(\"#e7d84a\")\n",
    "        elif nt == \"glut\":\n",
    "            color_list.append(\"#44d44b\")\n",
    "        elif nt == \"oct\":\n",
    "            color_list.append(\"#0084ff\")\n",
    "        elif nt == \"ser\":\n",
    "            color_list.append(\"#b65eff\")\n",
    "\n",
    "    # builds neuroglancer link using root IDs and list of custom colors #\n",
    "    link = tt.build_ng_link(root_ids, datastack, custom_colors=color_list)\n",
    "\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd36f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots_to_nt_link([720575940625342472,720575940627818499,720575940631449916,720575940651305718,720575940618680550,720575940626405690], \"flywire_fafb_production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ad958",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### ROOT ID ROUGH SPOT CHECKER ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d27dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ng_link(\n",
    "    root_ids,\n",
    "    datastack,\n",
    "    incoming=False,\n",
    "    outgoing=False,\n",
    "    cleft_thresh=0,\n",
    "    white=False,\n",
    "    custom_colors=False,\n",
    "    bbox_coord_list=False\n",
    "):\n",
    "    \"\"\"Build a neuroglancer state url from a list of root IDs.\n",
    "\n",
    "    Arguments:\n",
    "    root_ids -- a list of 18-digit root IDs (list of str)\n",
    "    datastack -- the name of the datastack the root IDs belong to (str)\n",
    "    incoming -- whether to include incoming synapses (bool, default False)\n",
    "    outgoing -- whether to include outgoing synapses (bool, default False)\n",
    "    cleft_thresh -- the cleft score threshold below which to exclude synapses, currently only works for flywire (int, default 0)\n",
    "    white -- whether or not to make all the segment colors white (bool, default False)\n",
    "    custom_colors -- if a list of hex values is passed they will be used to color the neurons in the same order as the root_ids list (list of str, default False)\n",
    "    bbox_coord_list -- option to add one or more bounding boxes to the final link by inputting their corner coordinates, e.g. for two [[[147355, 59771, 3184],[148090, 60226, 3064]],[[147883, 60485, 3064],[148460, 61040, 2964]]] (list of lists of lists of ints)\n",
    "    \n",
    "    Returns:\n",
    "    ng_url -- the url for the constructed neuroglancer state (str)\n",
    "    \"\"\"\n",
    "\n",
    "    ### CURRENTLY ASSUMES ROOT COLUMN NAMES ARE \"pre/post_pt_root_id\" ###\n",
    "    ### CURRENTLY ASSUMES COORD COLUMN NAMES ARE \"pre/post_pt_position\" ###\n",
    "\n",
    "    ### CURRENTLY ASSUMES CLEFT SCORE COLUMN NAME IS \"cleft_score\", ONLY WORKS WITH FLYWIRE ###\n",
    "    cleft_score_column_name = \"cleft_score\"\n",
    "\n",
    "    # sets CAVE client object using datastack name #\n",
    "    client = CAVEclient(datastack_name=datastack)\n",
    "\n",
    "    # gets metadata for chosen datastack as dict #\n",
    "    stack_info = client.info.get_datastack_info()\n",
    "\n",
    "    # gets base url from stack info #\n",
    "    base_url = stack_info[\"viewer_site\"]\n",
    "\n",
    "    # gets viewer resolution from stack info #\n",
    "    viewer_res = [\n",
    "        stack_info[\"viewer_resolution_x\"],\n",
    "        stack_info[\"viewer_resolution_y\"],\n",
    "        stack_info[\"viewer_resolution_z\"],\n",
    "    ]\n",
    "\n",
    "    # if synapses are requested, sets name of synapse table using metadata #\n",
    "    if incoming == True or outgoing == True:\n",
    "        synapse_table_name = stack_info[\"synapse_table\"]\n",
    "\n",
    "    # determines names of synapse table columns and ng tabs based on arguments #\n",
    "    # also sets syn_state variable for use later #\n",
    "    if incoming == True and outgoing == False:\n",
    "        syn_state = \"in\"\n",
    "        syn_col_name_1 = \"post_pt_root_id\"\n",
    "        syn_tab_name_1 = \"Incoming Synapses\"\n",
    "    elif outgoing == True and incoming == False:\n",
    "        syn_state = \"out\"\n",
    "        syn_col_name_1 = \"pre_pt_root_id\"\n",
    "        syn_tab_name_1 = \"Outgoing Synapses\"\n",
    "    elif incoming == True and outgoing == True:\n",
    "        syn_state = \"both\"\n",
    "        syn_col_name_1 = \"post_pt_root_id\"\n",
    "        syn_tab_name_1 = \"Incoming Synapses\"\n",
    "        syn_col_name_2 = \"pre_pt_root_id\"\n",
    "        syn_tab_name_2 = \"Outgoing Synapses\"\n",
    "    else:\n",
    "        syn_state = \"none\"\n",
    "\n",
    "    # converts root IDs to integers for passing into query_table method #\n",
    "    root_ids = list(map(int, root_ids))\n",
    "\n",
    "    # creates empty list to populate with annotation dfs #\n",
    "    anno_df_list = []\n",
    "\n",
    "    # queries synapse table based on arguments #\n",
    "    if syn_state != \"none\":\n",
    "        syn_df_1 = client.materialize.query_table(\n",
    "            synapse_table_name,\n",
    "            filter_in_dict={syn_col_name_1: root_ids},\n",
    "        )\n",
    "\n",
    "        # removes synapses with cleft scores below threshold #\n",
    "        if cleft_thresh > 0.0:\n",
    "            syn_df_1 = syn_df_1[\n",
    "                syn_df_1[cleft_score_column_name] >= float(cleft_thresh)\n",
    "            ].reset_index(drop=True)\n",
    "        # makes df of just the coordinates converted into viewer resolution #\n",
    "        syn_coords_df_1 = pd.DataFrame(\n",
    "            {\n",
    "                \"pre\": [\n",
    "                    [coord / res for coord, res in zip(point, viewer_res)]\n",
    "                    for point in syn_df_1[\"pre_pt_position\"]\n",
    "                ],\n",
    "                \"post\": [\n",
    "                    [coord / res for coord, res in zip(point, viewer_res)]\n",
    "                    for point in syn_df_1[\"post_pt_position\"]\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        # adds df of synapse coords to list for passing into statebuilder #\n",
    "        anno_df_list.append(syn_coords_df_1)\n",
    "        # gets count of number of synapses #\n",
    "        syn_count_1 = len(syn_coords_df_1)\n",
    "\n",
    "        # repeats the process for the second direction if both incoming and outgoing are requested #\n",
    "        if syn_state == \"both\":\n",
    "            syn_df_2 = client.materialize.query_table(\n",
    "                synapse_table_name,\n",
    "                filter_in_dict={syn_col_name_2: root_ids},\n",
    "            )\n",
    "            if cleft_thresh > 0.0:\n",
    "                syn_df_2 = syn_df_2[\n",
    "                    syn_df_2[cleft_score_column_name] >= float(cleft_thresh)\n",
    "                ].reset_index(drop=True)\n",
    "            syn_coords_df_2 = pd.DataFrame(\n",
    "                {\n",
    "                    \"pre\": [\n",
    "                        [coord / res for coord, res in zip(point, viewer_res)]\n",
    "                        for point in syn_df_2[\"pre_pt_position\"]\n",
    "                    ],\n",
    "                    \"post\": [\n",
    "                        [coord / res for coord, res in zip(point, viewer_res)]\n",
    "                        for point in syn_df_2[\"post_pt_position\"]\n",
    "                    ],\n",
    "                }\n",
    "            )\n",
    "            anno_df_list.append(syn_coords_df_2)\n",
    "            syn_count_2 = len(syn_coords_df_2)\n",
    "\n",
    "    # makes empty list to fill with layers #\n",
    "    layer_list = []\n",
    "\n",
    "    # sets configuration for EM layer #\n",
    "    img = ImageLayerConfig(\n",
    "        name=\"EM\",\n",
    "        source=client.info.image_source(),\n",
    "    )\n",
    "\n",
    "    # adds EM layer to list #\n",
    "    layer_list.append(img)\n",
    "\n",
    "    seg_source = client.info.segmentation_source()\n",
    "    if datastack == \"brain_and_nerve_cord\":\n",
    "        split_url = seg_source.split(\"https\")\n",
    "        seg_source = split_url[0] + \"middleauth+https\" + split_url[1]\n",
    "\n",
    "    # determines color scheme for segmentation #\n",
    "    if white == True:\n",
    "        color_list = [\"#ffffff\" for x in root_ids]\n",
    "    elif custom_colors != False:\n",
    "        color_list = custom_colors\n",
    "    else:\n",
    "        color_list = tt.generate_color_list(len(root_ids), alternate_brightness=0.3)\n",
    "\n",
    "    # defines segmentation layer config #\n",
    "    seg = SegmentationLayerConfig(\n",
    "        name=\"Segmentation\",\n",
    "        source=seg_source,\n",
    "        fixed_ids=root_ids,\n",
    "        fixed_id_colors=color_list,\n",
    "    )\n",
    "\n",
    "    # adds segmentation layer to list #\n",
    "    layer_list.append(seg)\n",
    "\n",
    "    # creates empty list to fill with annotation layers\n",
    "    anno_layers = []\n",
    "\n",
    "    # defines synapse layer config(s) if requested #\n",
    "    if syn_state != \"none\":\n",
    "        # defines configuration for line annotations #\n",
    "        lines = LineMapper(\n",
    "            point_column_a=\"pre\",\n",
    "            point_column_b=\"post\",\n",
    "        )\n",
    "\n",
    "        if datastack == \"flywire_fafb_production\":\n",
    "            in_syn_color = \"#FFFF00\"\n",
    "            out_syn_color = \"#0000FF\"\n",
    "        else:\n",
    "            in_syn_color = \"#FF6E4A\"\n",
    "            out_syn_color = \"#3D81FF\"\n",
    "\n",
    "        # ensures consistent color coding for incoming and outgoing synapses #\n",
    "        if syn_state == \"out\":\n",
    "            syn_1 = AnnotationLayerConfig(\n",
    "                name=syn_tab_name_1,\n",
    "                mapping_rules=lines,\n",
    "                color=out_syn_color,\n",
    "            )\n",
    "        else:\n",
    "            syn_1 = AnnotationLayerConfig(\n",
    "                name=syn_tab_name_1,\n",
    "                mapping_rules=lines,\n",
    "                color=in_syn_color,\n",
    "            )\n",
    "        # layer_list.append(syn_1)\n",
    "        anno_layers.append(syn_1)\n",
    "        # repeats process if in and output synapses requested #\n",
    "        if syn_state == \"both\":\n",
    "            syn_2 = AnnotationLayerConfig(\n",
    "                name=syn_tab_name_2,\n",
    "                mapping_rules=lines,\n",
    "                color=out_syn_color,\n",
    "            )\n",
    "            anno_layers.append(syn_2)\n",
    "\n",
    "    # VIEW SET, CURRENTLY NONFUNCTIONAL #\n",
    "    if datastack == \"flywire_fafb_production\":\n",
    "        view_options = {\n",
    "            \"position\": [130900, 57662, 3052],\n",
    "            \"zoom_3d\": 6.64,\n",
    "        }\n",
    "    elif datastack == \"brain_and_nerve_cord\":\n",
    "        view_options = {\n",
    "            \"position\": [\n",
    "                127339,\n",
    "                142245,\n",
    "                3041,\n",
    "            ],\n",
    "            # \"zoom_3d\": 6.64,\n",
    "        }\n",
    "\n",
    "    # adds bounding box layer if user requests it #\n",
    "    if bbox_coord_list != False:\n",
    "        \n",
    "        # makes df out of coorindate list #\n",
    "        bbox_df = pd.DataFrame(\n",
    "            {\n",
    "                \"point_a\": [bbox[0] for bbox in bbox_coord_list],\n",
    "                \"point_b\": [bbox[1] for bbox in bbox_coord_list],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        anno_df_list.append(bbox_df)\n",
    "\n",
    "        print(bbox_df)\n",
    "        \n",
    "        # defines configuration for bbox annotations #\n",
    "        bbox_rules = BoundingBoxMapper(\n",
    "            point_column_a=\"point_a\",\n",
    "            point_column_b=\"point_b\",\n",
    "        )\n",
    "\n",
    "        # conditionally sets layer name plurality #\n",
    "        if len(bbox_coord_list) == 1:\n",
    "            bbox_layer_name = \"Bounding Box\"\n",
    "        else:\n",
    "            bbox_layer_name = \"Bounding Boxes\"\n",
    "\n",
    "        # defines annotation layer for bbox #\n",
    "        bbox_anno = AnnotationLayerConfig(\n",
    "            name=bbox_layer_name,\n",
    "            mapping_rules=bbox_rules,\n",
    "        )\n",
    "\n",
    "        anno_layers.append(bbox_anno)\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "    # PARTIAL CODE FOR BBOX QUERY, CURRENTLY UNUSED #\n",
    "    # ensures that all boxmin coords are less than their boxmax counterparts #\n",
    "    # if boxmin[0] > boxmax[0]:\n",
    "    #     temp = boxmax[0]\n",
    "    #     boxmax[0] = boxmin[0]\n",
    "    #     boxmin[0] = temp\n",
    "    # if boxmin[1] > boxmax[1]:\n",
    "    #     temp = boxmax[1]\n",
    "    #     boxmax[1] = boxmin[1]\n",
    "    #     boxmin[1] = temp\n",
    "    # if boxmin[2] > boxmax[2]:\n",
    "    #     temp = boxmax[2]\n",
    "    #     boxmax[2] = boxmin[2]\n",
    "    #     boxmin[2] = temp\n",
    "    \n",
    "    # # queries synapse table for synapses in bbox #\n",
    "    # syn_df1 = client.materialize.query_table(\n",
    "    #     \"synapses_nt_v1\",                \n",
    "    #     filter_spatial_dict={\"pre_pt_position\": [boxmin,boxmax]},\n",
    "    # )\n",
    "    # syn_df2 = client.materialize.query_table(\n",
    "    #     \"synapses_nt_v1\",                \n",
    "    #     filter_spatial_dict={\"post_pt_position\": [boxmin,boxmax]},\n",
    "    # )\n",
    "    \n",
    "    # # concatenates pre and post queried dfs #\n",
    "    # syn_df = pd.concat([syn_df1,syn_df2],ignore_index=True)\n",
    "\n",
    "    # # drops duplicate entires from df #\n",
    "    # syn_df = syn_df.drop_duplicates(subset=['id'])\n",
    "\n",
    "    # # makes df of just synapse coords #\n",
    "    # syn_coords_df = pd.DataFrame(\n",
    "    #     {\n",
    "    #         \"pre\": [nmToNG(x, res) for x in syn_df[\"pre_pt_position\"]],\n",
    "    #         \"post\": [nmToNG(x, res) for x in syn_df[\"post_pt_position\"]],\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    " ###################################################################################\n",
    "\n",
    "    # chooses target site name based on datastack to handle pre-spelunker datasets #\n",
    "    if datastack == \"flywire_fafb_production\":\n",
    "        target_site_name = \"seunglab\"\n",
    "    else:\n",
    "        target_site_name = \"spelunker\"\n",
    "\n",
    "    # counts number of annotation layers #\n",
    "    anno_layer_num = len(anno_layers)\n",
    "\n",
    "    # behavior if there are no annotation layers #\n",
    "    if anno_layer_num == 0:\n",
    "        \n",
    "        # defines state builder by passing in rules for img, seg, and anno layers #\n",
    "        sb_1 = StateBuilder(\n",
    "            layer_list,\n",
    "            resolution=viewer_res,\n",
    "            # view_kws=view_options,\n",
    "        )\n",
    "        \n",
    "        # builds state json #\n",
    "        state_json = json.loads(\n",
    "            sb_1.render_state(\n",
    "                return_as=\"json\",\n",
    "                target_site=target_site_name,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # behavior if there is exactly 1 annotation layer #\n",
    "    elif anno_layer_num == 1:\n",
    "        \n",
    "        # adds annotation layer to layer list #\n",
    "        layer_list.append(anno_layers[0])\n",
    "        \n",
    "        # creates statebuilder #\n",
    "        sb_1 = StateBuilder(\n",
    "            layer_list,\n",
    "            resolution=viewer_res,\n",
    "            # view_kws=view_options,\n",
    "        )\n",
    "        \n",
    "        # builds state json with one annotation layer #\n",
    "        state_json = json.loads(\n",
    "            sb_1.render_state(\n",
    "                anno_df_list[0],\n",
    "                return_as=\"json\",\n",
    "                target_site=target_site_name,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # behavior if there are 2 or more annotation layers #\n",
    "    else:\n",
    "        # makes empty statebuilder list to populate for chained statebuilder #\n",
    "        sb_list = []\n",
    "\n",
    "        #adds first annotation layer to layer list for first statebuilder #\n",
    "        layer_list.append(anno_layers[0])\n",
    "\n",
    "        # makes first statebuilder #\n",
    "        sb_1 = StateBuilder(\n",
    "            layer_list,\n",
    "            resolution=viewer_res,\n",
    "            # view_kws=view_options,\n",
    "        )\n",
    "        # adds first statebuilder to statebuilder list #\n",
    "        sb_list.append(sb_1)\n",
    "\n",
    "        # iterates over remaining layers, making statebuilders for each and adding to list #\n",
    "        for layer in anno_layers[1:]:\n",
    "            sb = StateBuilder([layer],resolution=viewer_res)\n",
    "            sb_list.append(sb)\n",
    "\n",
    "        # makes chained statebuilder out of individuals #\n",
    "        chained_sb = ChainedStateBuilder(sb_list)\n",
    "\n",
    "        # makes state json using chained statebuilder and list of annotation dfs #\n",
    "        state_json = json.loads(\n",
    "            chained_sb.render_state(\n",
    "                anno_df_list,\n",
    "                return_as=\"json\",\n",
    "                target_site=target_site_name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # manually sets viewer angle based on dataset #\n",
    "    if datastack == \"flywire_fafb_production\":\n",
    "        state_json[\"perspectiveOrientation\"] = [\n",
    "            -0.029998891055583954,\n",
    "            -0.008902468718588352,\n",
    "            -0.02068145014345646,\n",
    "            -0.9992963075637817,\n",
    "        ]\n",
    "    elif datastack == \"brain_and_nerve_cord\":\n",
    "        state_json[\"perspectiveOrientation\"] = [\n",
    "            -0.006392207462340593,\n",
    "            -0.9995864033699036,\n",
    "            -0.0023922761902213097,\n",
    "            -0.02793547324836254,\n",
    "        ]\n",
    "\n",
    "    # sends JSON state to remote state server and gets back state ID #\n",
    "    new_state_id = client.state.upload_state_json(state_json)\n",
    "\n",
    "    # builds url using the state ID and the base url for the dataset #\n",
    "    url = client.state.build_neuroglancer_url(\n",
    "        state_id=new_state_id,\n",
    "        ngl_url=base_url,\n",
    "    )\n",
    "\n",
    "    # conditional synapse print based on user input #\n",
    "    if syn_state == \"in\":\n",
    "        print(\"Incoming Synapses:\", syn_count_1)\n",
    "    elif syn_state == \"out\":\n",
    "        print(\"Outgoing Synapses:\", syn_count_1)\n",
    "    elif syn_state == \"both\":\n",
    "        print(\"Incoming Synapses:\", syn_count_1)\n",
    "        print(\"Outgoing Synapses:\", syn_count_2)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8afd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ng_link([720575940625342472,720575940627818499,720575940631449916,720575940651305718,720575940618680550,720575940626405690], \"flywire_fafb_production\", incoming=False, outgoing=True,bbox_coord_list=[[[112521, 41993, 1595],[155287, 57562, 3349]],[[124387, 48074, 2093],[140105, 68117, 2994]],[[148352, 65261, 3343],[150240, 66971, 3093]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osteoid import Skeleton, Bbox\n",
    "from caveclient import CAVEclient\n",
    "# from cloudvolume import CloudVolume\n",
    "import numpy as np\n",
    "import microviewer\n",
    "import time\n",
    "import sys\n",
    "import gspread\n",
    "import pandas as pd\n",
    "\n",
    "def check_root_intersect(root_list, datastack=\"brain_and_nerve_cord\",visualize=False):\n",
    "\tclient = CAVEclient(datastack)\n",
    "\n",
    "\tif datastack == \"brain_and_nerve_cord\":\n",
    "\t\tbbox_list = [\n",
    "\t\t\tBbox([86240, 24188, 1504],[100628, 41809, 2229]), # tunnel of death #\n",
    "\t\t\tBbox([85969, 34825, 2230],[100310, 44999, 2959]), # tunnel of death #\n",
    "\t\t\tBbox([89471, 35922, 2935],[113945, 46013, 3691]), # tunnel of death #\n",
    "\t\t\tBbox([113941, 38078, 3195],[126443, 48442, 3691]), # tunnel of death #\n",
    "\t\t\tBbox([126446, 35586, 3145],[139404, 45760, 3691]), # tunnel of death #\n",
    "\t\t\tBbox([139380, 35978, 3007],[150973, 42310, 3506]), # tunnel of death #\n",
    "\t\t\tBbox([146357, 35253, 2605],[153882, 41070, 3005]), # tunnel of death #\n",
    "\t\t\tBbox([149234, 34279, 2019],[153801, 39355, 2603]), # tunnel of death #\n",
    "\t\t\tBbox([99778, 176438, 3251],[ 104086, 181975, 3687]), # T2 blowout #\n",
    "\t\t\tBbox([146730, 194587, 4441],[148357, 198226, 4616]), # T1 Soup #\n",
    "\t\t\tBbox([116523, 204075, 5478],[119830, 208313, 5620]), # champagne patch #\n",
    "\t\t\tBbox([114396, 201794, 5620],[123629, 209989, 5882]), # champagne patch #\n",
    "\t\t\tBbox([115172, 202544, 5885],[122619, 211033, 5975]), # champagne patch #\n",
    "\t\t\tBbox([111512, 200317, 5975],[124825, 215415, 6385]), # champagne patch #\n",
    "\t\t\tBbox([116261, 205698, 6385],[122632, 213127, 6495]), # champagne patch #     \n",
    "\t\t]\n",
    "\n",
    "\tpbbx_list = [bbox.convert_units(\"nm\", resolution=[4,4,45]) for bbox in bbox_list]\n",
    "\n",
    "\tmatrix = np.array([\n",
    "\t[16, 0, 0, 0],\n",
    "\t[0, 16, 0, 0],\n",
    "\t[0, 0, 45, 0],\n",
    "\t], dtype=np.float32)\n",
    "\n",
    "\tseconds = client.skeleton.generate_bulk_skeletons_async(root_list, skeleton_version=-1)\n",
    "\n",
    "\tif isinstance(seconds, dict):\n",
    "\t\tprint(\"Bad root id.\")\n",
    "\t\tsys.exit(0)\n",
    "\n",
    "\tprint(f\"ETA {seconds} seconds.\")\n",
    "\ttime.sleep(seconds)\n",
    "\n",
    "\tcskel_list = [client.skeleton.get_skeleton(i) for i in root_list]\n",
    "\n",
    "\tpskel_list = [Skeleton(vertices=c['vertices'], edges=c['edges'], radii=c['radius'], transform=matrix, space=\"physical\") for c in cskel_list]\n",
    "\n",
    "\tif visualize == True:\n",
    "\t\tviewer_list = pskel_list + pbbx_list\n",
    "\t\tmicroviewer.objects(viewer_list)\n",
    "\n",
    "\tdef check_skel(pskel, bbox_list):\n",
    "\t\tskel_intersect = False\n",
    "\t\tfor box in bbox_list:\n",
    "\t\t\tcrop_skel = pskel.crop(box)\n",
    "\t\t\tif not crop_skel.empty():\n",
    "\t\t\t\tskel_intersect = True\n",
    "\t\treturn skel_intersect\n",
    "\n",
    "\tintersect_list = [check_skel(skel, pbbx_list) for skel in pskel_list]\n",
    "\n",
    "\treturn intersect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ids_from_gsheet(sheet_key):\n",
    "\tgc = gspread.oauth()\n",
    "\tspreadsheet = gc.open_by_key(sheet_key)\n",
    "\ttab = spreadsheet.sheet1\n",
    "\troots = tab.col_values(1)\n",
    "\tintersect_list = check_root_intersect(roots)\n",
    "\n",
    "\tdf = pd.DataFrame({\n",
    "\t\t\"root_ids\":roots,\n",
    "\t\t\"intersect_rough\":intersect_list,\n",
    "\t})\n",
    "\n",
    "\ttab.update([df.columns.values.tolist()] + df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063392f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## CODE TO DIRECTLY QUERY CHANGELOG, CURRENTLY NONFUNCTIONAL ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_edits_json(datastack, start, end)\n",
    "\n",
    "    def get_auth_token():\n",
    "    \"\"\"Find and return the local CAVE client auth token.\n",
    "\n",
    "    Returns:\n",
    "        auth_token: CAVEClient user authorization token (str)\n",
    "    \"\"\"\n",
    "    f = open(\"authtoken.txt\", \"r\")\n",
    "    auth_token = f.read()\n",
    "    f.close()\n",
    "    return auth_token\n",
    "\n",
    "    # sets client using datastack name #\n",
    "    client = CAVEclient(datastack_name=datastack)\n",
    "\n",
    "    # pulls datastact info dictionary using stack name #\n",
    "    stack_info = client.info.get_datastack_info()\n",
    "\n",
    "    cg_url = stack_info[\"segmentation_source\"]\n",
    "    # split_url = url.split(\"https\")\n",
    "    # chunkedgraph_url = split_url[0] + \"middleauth+https\" + split_url[1]\n",
    "\n",
    "    # builds query url #\n",
    "    url = f\"{cg_url}/tabular_change_log_recent?{start_arg}={str(start)}&{end_arg}={str(end)}&middle_auth_token={auth_token}\"\n",
    "\n",
    "    # uses query url to send a request for all the edits to a given dataset in a given timeframe #\n",
    "    r = requests.get(url)\n",
    "\n",
    "    # converts the result of the request into json format #\n",
    "    json = r.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
